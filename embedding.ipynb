{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d180d54",
   "metadata": {},
   "source": [
    "pourquoi?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f48786",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# basic imports\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# display matplotlib graphics in notebook\n",
    "%matplotlib inline \n",
    "import seaborn as sns\n",
    "\n",
    "# disable warnings for libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# configure logger\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s %(levelname)s:%(message)s', level=logging.INFO, datefmt='%I:%M:%S')\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d757ab9e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Installation : pip install shap\n",
    "import shap\n",
    "\n",
    "# Cette fonction permet de lier le texte brut à la décision du modèle\n",
    "def predict_proba(texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # On utilise le vecteur CLS pour la prédiction finale (à adapter selon votre classifieur)\n",
    "        emb = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "    return clf.predict_proba(emb)\n",
    "\n",
    "# Expliquer une prédiction sur un manifeste spécifique\n",
    "explainer = shap.Explainer(predict_proba, tokenizer)\n",
    "shap_values = explainer(df_final['clean_text'].iloc[:5]) # Analyse des 5 premiers\n",
    "\n",
    "# Visualisation (génère un graphique interactif en couleurs)\n",
    "shap.plots.text(shap_values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c934482",
   "metadata": {},
   "source": [
    "Le Support (titulaire-support) : Maintenant que vous avez features (vos X) et df_final['titulaire-support'] (vos Y), vous pouvez entraîner un classifieur classique très puissant comme un Random Forest ou un SVM.\n",
    "\n",
    "Gestion de la longueur : Le paramètre truncation=True est vital. Les manifestes de 81 sont longs ; ici, on ne garde que les 512 premiers tokens (environ les 300 premiers mots) pour l'embedding. Souvent, cela suffit largement à identifier la couleur politique d'un texte.\n",
    "\n",
    "Vitesse : L'utilisation de batch_size=16 permet d'accélérer le calcul par rapport à une boucle ligne par ligne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4537c54",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Définition des cibles (étiquettes politiques)\n",
    "y = df_final['titulaire-support']\n",
    "\n",
    "# Split Entraînement / Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features.numpy(), y, test_size=0.2)\n",
    "\n",
    "# Entraînement\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Score de précision sur 1981 : {clf.score(X_test, y_test):.2%}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
